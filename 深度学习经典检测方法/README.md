# YOLO 系列：

## 深度学习经典检测方法：
- two-stage（两阶段）：Faster-rcnn Mask-Rcnn 系列
  - 速度通常较慢（5FPS），但是效果通常是不错的！
  - 非常实用的通用框架 MaskRcnn，建议熟悉下！
- one-stage（单阶段）：YOLO 系列
  - 最核心优势：速度非常快，适合做实时检测任务！
  - 但是缺点也是有的，就是效果通常情况下不会太好！



## YOLO-V1
- 经典的 one-stage方法
- You Only Look Once，名字就已经说明一切！
- 把检测问题转化成回归问题（预测x y坐标，和 w h 长宽），一个 CNN 就搞定了！
- 可以对视频进行实时检测，应用领域非常广！

- 优点：快速、简单！
- 问题一：每个 cell 只预测一个类别，如果重叠无法解决
- 问题二：小物体检测效果一般，长宽比可选的但单一

## YOLO-V2
- YOLO-V-Batch Normalization
  - V2 版本舍弃 Dropout，卷积后全部加入 Batch Normalization
  - 网络的每一层的输入都做了归一化，收敛相对更容易
  - 经过 Batch Normalization 处理后的网络会提升 2% 的 mAP
  - 从现在的角度来看，Batch Normalization 已经成网络必备处理

- YOLO-V2-更大的分辨率
  - V1 训练时用的是 224 * 224，测试时使用 448 * 448
  - 可能导致模型水土不服，V2 训练时额外又进行了 10 次 448 * 488 的微调
  - 使用高分辨率分类器后，YOLO v2 的 mAP 提升了约 4%

### YOLO-V2 网络结构
- DarkNet，实际输入为 416 * 416
- 没有 FC 层，5 次降采样，（13 * 13）
- 1 * 1卷积节省了很多参数

### YOLO-V2 聚类提取先验框
- faster-rcnn 系列选取的先验框比例都是常规的（随便给的），但是不一定完全适合数据集
- K-means聚类中的距离： d = 1 - IOU，源码中 k = 5

### YOLO-V2 Anchor Box
- 通过引入 anchor boxes，使得预测的 box 数量更多（13\*13\*n）
- 跟 faster-rcnn 系列不同的是先验框并不是直接按照长宽固定比给定

### YOLO-V2 Fine-Grained Features
- 最后一层时感受野太大了，小目标可能丢失了，需融合之前的特征

### YOLO-V Multi-Scale
- 都是卷积操作可没人能限制我了！一定 iterations 之后改变输入图片大小
  - 最小的图像尺寸为 320 × 320
  - 最大的图像尺寸为 608 × 608

### 感受野：
定义：概括来说就是特征图上的点能看到原始图像多大区域！

### 为什么多数用 3 * 3 的卷积核：
- 假设输入大小都是 h * w * c，并且都使用 c 个卷积核（得到 c 个特征图），可以计算一下其各自所需参数：
  - 一个 7 * 7 卷积核所需参数： c × (7 × 7 × c) = 49 c2
  - 三个 3 * 3 的卷积核所需参数：3 × c × (3 × 3 × c) = 27c2
- 堆叠小的卷积核所需的参数更少一些，并且卷积过程越多，特征提取也会越细致，加入的非线性变换也随着增多，还不会增大权重参数个数，这就是 VGG 网络的基本出发点，用小的卷积核来完成特征提取操作。

## YOLO-V3
- 终于到 V3 了，最大的改进就是网络结构，使其更适合小目标检测
- 特征做的更细致，融入多持续特征图信息预测不同规格物体
- 先验框更丰富了，3 钟 scale，每种 3 个规格，一共 9 钟
- softmax 改进，预测多标签任务

### 多 Scale
- 为了能检测到不同大小的物体，设计了 3 个 scale

### scale 变换经典方法
- 图像金字塔（不适合，每一层都要提取特征，然后预测，速度慢）
- 只对金字塔最顶层的值作为结果值（缺点：感受野比较大，只提取了大特征，忽略小特征）
- 对不同的特征图分别利用（缺点，特征图比较小一般预测比较好，但是特征图中等和下等一般预测没那么好）
- 不同的特征图融合（大目标的特征图进行上采样然后和中目标的特征图进行融合）后再进行预测

### 残差连接：
- 从今天的角度来看，基本所有网络架构都用上了残差连接的方法
- V3 中也用了 resnet 的思想，堆叠更多的层来进行特征提取

### 核心网络架构：
- 没有池化和全连接层，全部卷积
- 下采样通过 stride 为 2 实现
- 3 种 scale。更多先验框
- 基本上当下经典做法全融入了

### 先验框设计：
- YOLO-V2 中选了 5 个，这回更多了，一共有 9 种，通过 聚类得到9 种先验框，根据大小分别用在不同的特征图上面
  - 13 * 13 特征图上：(116×90)，(156×198)，(373×326)
  - 26 * 26 特征图上：(30×61)，(62×45)，(59×119)
  - 51 * 52 特征图上：(10×13)，(16×30)，(33×23)

### softmax 层替代：
- 物体检测任务中可能一个物体有多个标签
- logistic激活函数来完成，这样就能预测每一个类别 是 / 不是

## YOLO-V4

### Bag of freebies(BOF)
- 只增加训练成本，但是能显著提高精度，并不影响推理速度
- 数据增强：调整亮度、对比对、色调、随机缩放、剪切、翻转、旋转
- 网络正则化的方法：Dropout、Dropblock等
- 类别不平衡，损失函数设计

#### 马赛克数据增强：
- 方法很简单，参考 cutMix 然后四张图片拼接成一张进行训练

#### 数据增强：
- Random Erase：用随机值或训练集的平均像素值替代图像的区域
- Hide and Seek：根据概率值设置随机隐藏一些补丁

#### Self-adversarial-training（SAT）
- 通过引入噪音点来增加游戏难度

#### Dropblock：
- 之前的 dropout 是随机选择点，现在吃掉一个区域

#### 标签平滑：
- 神经网络最大的缺点：自觉不错（过拟合），让它别太自信
- 例如原来标签为 (0, 1): [0, 1] × (1 - 0.1) + 0.1/2 = [0.05, 0.95]

### Bag of specials（BOS）
- 增加稍许推断代价，但可以提高模型精度的方法
- 网络细节部分加入了很多改进，引入了各种能让特征提取更好的方法
- 注意力机制，网络细节设计，特征金字塔等，你能想到的都有

#### SPP Net
- V3中为了更好满足不同输入大小，训练时改变输入数据大小
- SPP其实就是用最大池化来满足最终输入特征一致即可

#### CSP Net
- 每一个 block 按照特征图的 channel 维度拆分成两部分（这里分成两部分进行channel降维可以减少计算量，速度提升，精度没有下降反而有略微提高）
- 一份正常走网络，另一份直接 concat 到这个 block 的输出

### 激活函数：Mish
- 别一棒子打死，给个改过自新的机会
- Relu 有点太绝对了，Mish更符合实际
- 但是计算量确实增加了，效果会提升一点


# Mask Rcnn:

## FPN层的作用：
- R-CNN 中仅使用最后一层特征图进行特征提取，但是顶层特征中忽略了小物体的一些信息使得检测效果并不好，这该如何改进呢？
- FPN网络基本架构：特征金字塔网络（既进行特征提取，又进行特征融合）
- 基本思想：将多个阶段特征图融合在一起，这就相当于既有了高层的语义特征也有了低层的轮廓特征
- Resnet 101 的五个阶段：
  - 不改变特征图大小的层归为一个阶段
  - 每次抽取的特征都是每个阶段的最后一层的输出
  - 问题：特征图大小会发生变化，如何融合？通过上采样使特征图大小一致

## 根据特征图生成所有候选框：

## RPN层的作用：
- 跟 Faster R-CNN 的 RPN 层基本一样
  - 做一个二分类（2k 判断候选框中是前景还是背景）---分类
  - 做一个微调（4k 4是候选框中四个值 xy坐标 wh长宽值）---回归
- 这个 RPN 层 与 Faster-RCNN 中 RPN 层的区别：
  - 在 Faster R-CNN 中只对一层特征图进行 RPN，在 Mask R-CNN 中对 p2 - p6 五层特征图进行 RPN
  - 进行共享卷积，就是对 P2 - P6 这五个特征图都用 3 × 3 进行卷积，得到特征图个数 512，然后对 2k 和 4k 都进行 1 × 1 的卷积


## Proposal层：
- 对 20W+ 候选框进行过滤，先按照前景得分排序（得分：刚刚 二分类 得到的值）
- 取 6000 个得分最高的，把之前得到的每个框回归值都利用上（把框朝着刚刚的回归值方向进行移动），里面也有一些细节比如：把移动后的超越边界的删除掉
- 在进行 NMS 过滤（非极大值过滤）（按照 IOU 的值进行过滤，只取最大值，其他全部过滤掉）


## DetectionTarget层：
- 之前得到了 2000 个ROI（2000个候选位置），可能有 pad 进来的（0充数的）这些去掉
- 有的数据集一个框会包含多个物体，这样情况剔除掉
- 判断正负样本，基于 ROI （候选框）和 GT（真实位置） ，通过 IOU 与默认阈值 0.5 判断
- 设置负样本数量是正样本的 3 倍，总数默认 400 个（这里设置 1:3 比例估计是为了训练结果更好）
- 每一个正样本（ROI），需要得到其类别，用IOU最大的那个 GT（GT有类别，所以找到举例 ROI 的IOU最大的GT，其GT的类别就是ROI的类别）
- 每一个正样本，需要得到其与GT-Box的偏移量
- 每一个正样本，需要得到其最接近的GT-Box对应的MASK（这个MASK可以用来做分割，正样本拿 1填充，负样本拿 0 填充）
- 返回所有结果，其中负样本偏移量和MASK都用 0 填充

## RoiPooling层与RoiAlign层：
RoiPooling层问题：
- 两次量化，使得特征图对应位置不对
- 虽然特征图上差的不多，但是映射回原图就差得多了

RoiAlign层：用来统一特征图的大小的






